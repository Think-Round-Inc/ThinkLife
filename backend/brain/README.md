# ThinkLife Brain Architecture

## ğŸ§  Overview

The Brain is organized into two core engines that work together to process agent requests:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BRAIN CORE                             â”‚
â”‚               (Processes Agent Requests)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  REASONING ENGINE    â”‚  â”‚ WORKFLOW ENGINE   â”‚
        â”‚  "Thinking"          â”‚  â”‚  "Orchestrator"   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       REGISTRIES (Tools, Data, Providers)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Reasoning Engine
**"Brain inside the Brain"**

Uses LLMs to make intelligent decisions about next steps.

### Responsibilities
- ğŸ¤” **Decide next steps** based on context and history
- ğŸ› ï¸ **Choose tools** appropriate for the task
- ğŸ“Š **Select data sources** to query
- ğŸ”„ **Refine plans** based on intermediate results

### Characteristics
- âš¡ **Short-lived** - Per-request lifetime
- ğŸ¯ **Context-driven** - Strongly tied to prompts and context
- ğŸ§  **LLM-powered** - Uses provider registry for LLM access

### Location
```
backend/brain/reasoning/
â”œâ”€â”€ __init__.py
â””â”€â”€ reasoning_engine.py
```

### Usage
```python
from brain.cortex import get_reasoning_engine

reasoning = get_reasoning_engine()
await reasoning.initialize()

# Decide next step
decision = await reasoning.decide_next_step(
    request=brain_request,
    provider_spec=provider_spec,
    context=context,
    execution_history=history
)

# Select tools
tools = await reasoning.select_tools(
    request=brain_request,
    provider_spec=provider_spec,
    available_tools=["tavily_search", "document_summarizer"]
)

# Refine plan
refinement = await reasoning.refine_plan(
    original_request=brain_request,
    provider_spec=provider_spec,
    results_so_far=results,
    remaining_iterations=3
)
```

---

## âš™ï¸ Workflow Engine
**"Industrial-grade orchestrator"**

Ensures reliable execution with enterprise-grade features.

### Responsibilities
- ğŸ”„ **Retry logic** with exponential backoff
- â±ï¸ **Timeout handling** for long-running tasks
- ğŸ“… **Scheduling** and task queuing
- ğŸ” **Idempotency** support
- ğŸ“Š **State management** (durable state machine)
- ğŸ¯ **DAG execution** with workers

### Characteristics
- ğŸ—ï¸ **Long-running** - Supports multi-hour workflows
- ğŸ›¡ï¸ **Fault-tolerant** - Auto-retry on failures
- ğŸ“ˆ **Scalable** - Worker-based execution
- ğŸ’¾ **Durable** - State persistence

### Location
```
backend/brain/workflow/
â”œâ”€â”€ __init__.py
â””â”€â”€ workflow_engine.py
```

### Usage
```python
from brain.cortex import get_workflow_engine, WorkflowStep

workflow = get_workflow_engine()
await workflow.initialize()

# Define workflow steps
steps = [
    WorkflowStep(
        step_id="reason",
        name="Decide next action",
        action="reason",
        params={"decision": "next_step"},
        max_retries=3,
        timeout=30.0
    ),
    WorkflowStep(
        step_id="query",
        name="Query data",
        action="query_data",
        params={"query": "search term", "limit": 5},
        max_retries=2,
        timeout=15.0
    ),
    WorkflowStep(
        step_id="tool",
        name="Use tool",
        action="use_tool",
        params={"tool_name": "tavily_search", "tool_params": {}},
        max_retries=3,
        timeout=45.0
    )
]

# Execute workflow
execution = await workflow.execute_workflow(
    workflow_name="agent_request_processing",
    steps=steps,
    context={"request_id": "123"},
    idempotency_key="unique-key-123"
)

# Check status
print(execution.status)  # COMPLETED, FAILED, etc.
print(execution.results)  # Results from each step
```

---

## ğŸ“‹ Registries

Both engines use these registries to access resources:

### Provider Registry
Validates and manages LLM providers (OpenAI, Anthropic, Gemini).

```python
from brain.providers import check_provider_spec_availability

is_valid, errors, info = check_provider_spec_availability(provider_spec)
```

### Tool Registry
Auto-discovers and manages tools.

```python
from brain.tools import get_tool_registry

registry = get_tool_registry()
result = await registry.execute_tool("tavily_search", query="AI research")
```

### Data Source Registry
Manages and queries data sources (Vector DB, etc.).

```python
from brain.data_sources import get_data_source_registry

registry = get_data_source_registry()
results = await registry.query_best("semantic search query", k=5)
```

---

## ğŸ”„ Request Flow

```
1. Plugin sends AgentExecutionSpec to Brain Core
   â†“
2. Brain Core initializes Reasoning + Workflow Engines
   â†“
3. Reasoning Engine decides execution plan
   â†“
4. Workflow Engine executes plan reliably
   â”œâ†’ Query data sources (via registry)
   â”œâ†’ Use tools (via registry)
   â””â†’ Call LLM providers (via registry)
   â†“
5. Return results to plugin
```

---

## ğŸ“ Directory Structure

```
backend/brain/
â”œâ”€â”€ cortex/                 # Cortex - Central orchestrator + engines
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cortex.py           # Main orchestrator
â”‚   â”œâ”€â”€ reasoning_engine.py # Reasoning Engine
â”‚   â””â”€â”€ workflow_engine.py   # Workflow Engine
â”‚
â”œâ”€â”€ specs/                  # All specifications & types
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core_specs.py       # Brain, request/response, user context
â”‚   â”œâ”€â”€ provider_specs.py   # Provider types & configs
â”‚   â”œâ”€â”€ tool_specs.py       # Tool specifications
â”‚   â”œâ”€â”€ data_source_specs.py # Data source types & interfaces
â”‚   â”œâ”€â”€ guardrails_specs.py # Security specifications
â”‚   â”œâ”€â”€ workflow_specs.py   # Workflow types
â”‚   â”œâ”€â”€ reasoning_specs.py  # Reasoning types
â”‚   â””â”€â”€ agent_specs.py      # Agent interfaces & specs
â”‚
â”œâ”€â”€ providers/              # Provider Registry + Implementations
â”‚   â”œâ”€â”€ provider_registry.py
â”‚   â”œâ”€â”€ openai.py
â”‚   â”œâ”€â”€ anthropic.py
â”‚   â””â”€â”€ gemini.py
â”‚
â”œâ”€â”€ data_sources/           # Data Source Registry + Connectors
â”‚   â”œâ”€â”€ data_source_registry.py
â”‚   â””â”€â”€ vector_db.py
â”‚
â”œâ”€â”€ tools/                  # Tool Registry + Implementations
â”‚   â”œâ”€â”€ tool_registry.py
â”‚   â”œâ”€â”€ base_tool.py
â”‚   â””â”€â”€ tavily_search.py
â”‚
â””â”€â”€ guardrails/            # Guardrails & Security Management
    â””â”€â”€ security_manager.py

```

---

## ğŸ¯ Key Benefits

### Reasoning Engine
âœ… **Smart decisions** - LLM-powered reasoning  
âœ… **Context-aware** - Uses full conversation history  
âœ… **Adaptive** - Can adjust plans based on results

### Workflow Engine
âœ… **Reliable** - Automatic retries with backoff  
âœ… **Timeout-safe** - No hanging requests  
âœ… **Idempotent** - Safe to retry  
âœ… **Durable** - Long-running workflow support  
âœ… **Observable** - Full execution history

---

## ğŸš€ Getting Started

```python
from brain import CortexFlow
from brain.specs import AgentExecutionSpec, ProviderSpec, BrainRequest

# Initialize CortexFlow
cortex = CortexFlow()
await brain.initialize()

# Create execution spec from agent
spec = AgentExecutionSpec(
    provider=ProviderSpec(provider_type="openai", model="gpt-4o-mini"),
    data_sources=[...],
    tools=[...],
    processing=ProcessingSpec(max_iterations=3)
)

# Execute through Brain Core
# Reasoning Engine decides what to do
# Workflow Engine ensures reliable execution
result = await brain.execute_agent_request(spec, request, messages)
```

---

## ğŸ“– Philosophy

**Reasoning Engine** = Intelligence  
**Workflow Engine** = Reliability  
**Brain Core** = Orchestration  

Together they provide an **intelligent, reliable, scalable** AI system.

